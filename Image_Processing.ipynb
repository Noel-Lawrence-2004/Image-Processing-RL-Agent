{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51513f46",
      "metadata": {
        "id": "51513f46"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-python\n",
        "!pip install yolov5\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51970a7b",
      "metadata": {
        "id": "51970a7b"
      },
      "outputs": [],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "AX7QJiWAUbfQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX7QJiWAUbfQ",
        "outputId": "196bd70f-fd74-42ee-a38b-384e80c938fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91934e8",
      "metadata": {
        "id": "c91934e8"
      },
      "source": [
        "# Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1bb99e4f",
      "metadata": {
        "id": "1bb99e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa74426-1d77-4848-ea3c-9418f9f1c605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4ca8b724",
      "metadata": {
        "id": "4ca8b724"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gym import spaces\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageEnhance\n",
        "from scipy.stats import entropy\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "from pathlib import Path\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "from collections import deque\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de3244de",
      "metadata": {
        "id": "de3244de"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model\n",
        "model = th.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "929be15e",
      "metadata": {
        "id": "929be15e"
      },
      "source": [
        "# The custom Gym Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "946941a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "946941a0",
        "outputId": "d43f8b27-f379-4e23-af7e-bc4b385f64d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class ImagePreprocessorEnv(gym.Env):\n",
        "\n",
        "    def __init__(self, img_dir , yolo_v5_model , steps = 5):\n",
        "        super().__init__()\n",
        "\n",
        "        # Storing the input args\n",
        "        self.img_dir = img_dir\n",
        "        self.yolo_v5_model = yolo_v5_model\n",
        "        self.steps = steps\n",
        "        self.current_image_index = 0\n",
        "        self.processed_image = None\n",
        "\n",
        "        # Loading all image file paths\n",
        "        self.img_paths = glob.glob(os.path.join(self.img_dir, '*.jpg'))\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0.0] * 3), # Brightness Contrast and Sharpness\n",
        "            high=np.array([1.0] * 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        #  action space\n",
        "        self.action_space = spaces.Box(\n",
        "            low=np.array([-1.0, -1.0, 0.0]), # Tuning the  Brightness, Contrast and Sharpness\n",
        "            high=np.array([1.0, 1.0, 1.0]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.yolo_v5_model.eval()\n",
        "\n",
        "        # Select the image each episode\n",
        "        img_path = self.img_paths[self.current_image_index]\n",
        "        self.current_image_index = (self.current_image_index + 1) % len(self.img_paths)\n",
        "\n",
        "        self.original_image = cv.imread(img_path)\n",
        "        self.original_image = cv.cvtColor(self.original_image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "        # initial processed = original\n",
        "        self.processed_image = self.original_image.copy()\n",
        "        self.last_conf = self.confidence(self.processed_image)\n",
        "\n",
        "        obs = self._get_observation()\n",
        "        return obs\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_val(value , min = 0 , max = 255):\n",
        "        return np.clip((value - min) / (max - min), 0.0, 1.0)\n",
        "\n",
        "\n",
        "    def _get_observation(self):\n",
        "        gray_image = cv.cvtColor(self.processed_image, cv.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Get the observation features\n",
        "        brightness = np.mean(gray_image) # mean brightness\n",
        "\n",
        "        contrast = np.std(gray_image)  # Difference in contrast\n",
        "\n",
        "        sharpness = cv.Laplacian(gray_image, cv.CV_64F).var() # Sharpness using variance of Laplacian\n",
        "\n",
        "        # Normalize features\n",
        "        obs = np.array([\n",
        "            self.normalize_val(brightness),\n",
        "            self.normalize_val(contrast, 0 , 64),\n",
        "            self.normalize_val(sharpness, 0, 1000),\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def confidence(self, image):\n",
        "\n",
        "        # The result of Yolov5s detection on the passed image\n",
        "        results = self.yolo_v5_model(image)\n",
        "\n",
        "        # If None\n",
        "        if results.pred[0].shape[0] == 0:\n",
        "            return 0.0\n",
        "        confs = results.pred[0][:, 4].cpu().numpy()\n",
        "\n",
        "        k = min(3, len(confs))  # top 3 objects, for example\n",
        "        return float(np.mean(np.sort(confs)[-k:]))\n",
        "\n",
        "\n",
        "\n",
        "    def transform(self, image, action):\n",
        "\n",
        "        img = Image.fromarray(image)\n",
        "\n",
        "        brightness_factor = 1.0 + action[0]\n",
        "        img = ImageEnhance.Brightness(img).enhance(brightness_factor)\n",
        "\n",
        "        contrast_factor = 1.0 + action[1]\n",
        "        img = ImageEnhance.Contrast(img).enhance(contrast_factor)\n",
        "\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        blur_strength = float(action[2])\n",
        "        if blur_strength > 0:\n",
        "            sigma = blur_strength * 0.5\n",
        "            img_np = cv.GaussianBlur(img_np, (0, 0), sigmaX=sigma)\n",
        "\n",
        "        return img_np\n",
        "\n",
        "\n",
        "    def reward_function(self, old_conf, new_conf):\n",
        "        return (new_conf - old_conf) + 0.05 * (new_conf)\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        old_conf = self.last_conf\n",
        "        self.processed_image = self.transform(self.processed_image, action)\n",
        "\n",
        "        new_conf = self.confidence(self.processed_image)\n",
        "\n",
        "        # reward\n",
        "        reward = self.reward_function(old_conf, new_conf)\n",
        "        self.last_conf = new_conf\n",
        "\n",
        "        obs = self._get_observation()\n",
        "\n",
        "        # done flag\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.steps\n",
        "\n",
        "        info = {\n",
        "            \"old_confidence\": old_conf,\n",
        "            \"new_confidence\": new_conf,\n",
        "            \"step\": self.current_step\n",
        "        }\n",
        "\n",
        "        return obs, reward, done, info\n",
        "\n",
        "\n",
        "    def render(self , image):\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d36a20b7",
      "metadata": {
        "id": "d36a20b7"
      },
      "source": [
        "# Actor Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3c8903e9",
      "metadata": {
        "id": "3c8903e9"
      },
      "outputs": [],
      "source": [
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, no_states, no_actions):\n",
        "        super().__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(no_states, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,no_actions)\n",
        "        )\n",
        "\n",
        "        # O/P activation fn\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, state):\n",
        "        state = state.to(device)\n",
        "        out = self.network(state)\n",
        "\n",
        "        # Applying the activation fn to the outputs\n",
        "        brightness = self.tanh(out[:, 0:1])\n",
        "        contrast = self.tanh(out[:, 1:2])\n",
        "        blur = self.sigmoid(out[:, 2:3])\n",
        "\n",
        "        # Concatenate the final action vector\n",
        "        action = th.cat([brightness, contrast, blur], dim=1)\n",
        "        return action\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, no_states, no_actions):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(no_states, 256)\n",
        "        self.fc2 = nn.Linear(256 + no_actions, 256)\n",
        "\n",
        "        # Q-value output n/w\n",
        "        self.q_out = nn.Linear(256, 1)\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        state = state.to(device)\n",
        "        state_out = F.relu(self.fc1(state))\n",
        "\n",
        "        x = th.cat([state_out, action], dim=1)\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        q_value = self.q_out(x)\n",
        "        return q_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "92c9168e",
      "metadata": {
        "id": "92c9168e"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        transition = random.sample(self.buffer, batch_size)\n",
        "        state, action, reward, next_state, done = zip(*transition)\n",
        "        return (\n",
        "            th.FloatTensor(state),\n",
        "            th.FloatTensor(action),\n",
        "            th.FloatTensor(reward),\n",
        "            th.FloatTensor(next_state),\n",
        "            th.FloatTensor(done),\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "abc9cb88",
      "metadata": {
        "id": "abc9cb88"
      },
      "outputs": [],
      "source": [
        "def soft_update(target_net, source_net, tau=0.005):\n",
        "    for target_param, source_param in zip(target_net.parameters(), source_net.parameters()):\n",
        "        target_param.data.copy_(tau * source_param.data + (1.0 - tau) * target_param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d9734295",
      "metadata": {
        "id": "d9734295"
      },
      "outputs": [],
      "source": [
        "# CONSTANTS\n",
        "GAMMA = 0.99 # Discount Factor\n",
        "TAU = 0.005 # Soft Update parameter\n",
        "BATCH_SIZE = 128 # Size of batch for replay buffer\n",
        "MAX_EPISODES = 1820 # Number of images to train\n",
        "MAX_STEPS = 5\n",
        "WARMUP_STEPS = 200\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "initial_noise = 0.5\n",
        "final_noise = 0.05\n",
        "updates_per_step = 3  # do multiple gradient updates per step\n",
        "rolling_window = 100     # smoothing window\n",
        "policy_noise = 0.2\n",
        "noise_clip = 0.5\n",
        "policy_delay = 2   # update actor every 2 critic updates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3048c3",
      "metadata": {
        "id": "9e3048c3"
      },
      "outputs": [],
      "source": [
        "img_directory = \"/content/drive/MyDrive/Atri Dataset/Train\"\n",
        "\n",
        "# Initializing the Env\n",
        "env = ImagePreprocessorEnv(img_directory, model)\n",
        "no_states = env.observation_space.shape[0]\n",
        "no_actions = env.action_space.shape[0]\n",
        "\n",
        "# Creating the Actor and Critic Networks\n",
        "\n",
        "actor = Actor(no_states, no_actions)\n",
        "target_actor = Actor(no_states, no_actions).to(device)\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=1e-4)\n",
        "\n",
        "critic1 = Critic(no_states, no_actions).to(device)\n",
        "critic2 = Critic(no_states, no_actions).to(device)\n",
        "target_critic1 = Critic(no_states, no_actions).to(device)\n",
        "target_critic2 = Critic(no_states, no_actions).to(device)\n",
        "\n",
        "critic1_optimizer = th.optim.Adam(critic1.parameters(), lr=3e-4)\n",
        "critic2_optimizer = th.optim.Adam(critic2.parameters(), lr=3e-4)\n",
        "\n",
        "# Copy params\n",
        "target_actor.load_state_dict(actor.state_dict())\n",
        "target_critic1.load_state_dict(critic1.state_dict())\n",
        "target_critic2.load_state_dict(critic2.state_dict())\n",
        "\n",
        "replay_buffer = ReplayBuffer(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5689ca84",
      "metadata": {
        "id": "5689ca84"
      },
      "outputs": [],
      "source": [
        "def add_noise(action, sigma=0.1):\n",
        "    noise =  np.random.normal(0, sigma, size=action.shape)\n",
        "\n",
        "    # Clip actions to valid range\n",
        "    action = np.clip(action + noise , [-1.0, -1.0, 0.0], [1.0, 1.0, 1.0])\n",
        "    return action"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "P0cQ5K8ewyYD"
      },
      "id": "P0cQ5K8ewyYD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b82858d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "3b82858d",
        "outputId": "9760eee2-ed8b-4b84-ee08-6391c3e497d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "total_updates = 0\n",
        "episode_rewards_list = []\n",
        "actor_losses_list = []\n",
        "critic_losses_list = []\n",
        "total_steps = 0\n",
        "noise_decay = (initial_noise - final_noise) / MAX_EPISODES\n",
        "\n",
        "# Training loop using TD3\n",
        "for episode in range(MAX_EPISODES):\n",
        "\n",
        "    # Get the state variables\n",
        "    state = env.reset()\n",
        "    episode_reward = 0\n",
        "\n",
        "    print(f\"Episode {episode+1}/{MAX_EPISODES}\")\n",
        "\n",
        "    for step in range(MAX_STEPS):\n",
        "\n",
        "        total_steps += 1\n",
        "        if total_steps < WARMUP_STEPS:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "\n",
        "            # Get action for current state\n",
        "            with th.no_grad():\n",
        "                state_tensor = th.FloatTensor(state).unsqueeze(0).to(device)\n",
        "                action = actor(state_tensor).cpu().numpy()[0]\n",
        "\n",
        "            noise = max(final_noise, initial_noise - episode * noise_decay)\n",
        "\n",
        "            # Add noise\n",
        "            action = add_noise(action, noise)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Store in replay buffer\n",
        "        replay_buffer.add(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "        episode_reward += reward\n",
        "\n",
        "\n",
        "        if len(replay_buffer) > BATCH_SIZE:\n",
        "            for g in range(updates_per_step):\n",
        "                total_updates += 1\n",
        "\n",
        "                states, actions, rewards, next_states, dones = replay_buffer.sample(BATCH_SIZE)\n",
        "\n",
        "                # Convert to tensors\n",
        "                states = th.FloatTensor(states).to(device)\n",
        "                actions = th.FloatTensor(actions).to(device)\n",
        "                rewards = th.FloatTensor(rewards).unsqueeze(1).to(device)\n",
        "                next_states = th.FloatTensor(next_states).to(device)\n",
        "                dones = th.FloatTensor(dones).unsqueeze(1).to(device)\n",
        "\n",
        "                with th.no_grad():\n",
        "                    # Target policy smoothing\n",
        "                    noise = (th.randn_like(actions) * policy_noise).clamp(-noise_clip, noise_clip)\n",
        "                    next_actions = (target_actor(next_states) + noise).clamp(-1, 1)\n",
        "\n",
        "                    # Compute target Q\n",
        "                    target_Q1 = target_critic1(next_states, next_actions)\n",
        "                    target_Q2 = target_critic2(next_states, next_actions)\n",
        "                    target_Q = th.min(target_Q1, target_Q2)\n",
        "                    target_Q = rewards + GAMMA * (1 - dones) * target_Q\n",
        "\n",
        "                # Update critics\n",
        "                current_Q1 = critic1(states, actions)\n",
        "                current_Q2 = critic2(states, actions)\n",
        "\n",
        "                critic1_loss = F.mse_loss(current_Q1, target_Q)\n",
        "                critic2_loss = F.mse_loss(current_Q2, target_Q)\n",
        "\n",
        "                critic1_optimizer.zero_grad()\n",
        "                critic1_loss.backward()\n",
        "                critic1_optimizer.step()\n",
        "\n",
        "                critic2_optimizer.zero_grad()\n",
        "                critic2_loss.backward()\n",
        "                critic2_optimizer.step()\n",
        "                critic_losses_list.append(min(critic1_loss.item() , critic2_loss.item()))\n",
        "\n",
        "\n",
        "                # Actor updates\n",
        "                if total_updates % policy_delay == 0:\n",
        "                    actor_loss = -critic1(states, actor(states)).mean()\n",
        "                    actor_optimizer.zero_grad()\n",
        "                    actor_loss.backward()\n",
        "                    actor_optimizer.step()\n",
        "                    actor_losses_list.append(actor_loss.item())\n",
        "\n",
        "                    # Soft update target networks\n",
        "                    soft_update(target_actor, actor, TAU)\n",
        "                    soft_update(target_critic1, critic1, TAU)\n",
        "                    soft_update(target_critic2, critic2, TAU)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Store rewards\n",
        "    episode_rewards_list.append(episode_reward)\n",
        "\n",
        "    # Live Plot\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.axhline(y=0.0, color='gray', linestyle='--', linewidth=1, label='Zero')\n",
        "    plt.plot(episode_rewards_list, label='Episode Reward')\n",
        "    if len(episode_rewards_list) >= rolling_window:\n",
        "        rewards_rolling = pd.Series(episode_rewards_list).rolling(rolling_window).mean()\n",
        "        plt.plot(rewards_rolling, label=f'Rolling Avg ({rolling_window})', color='red')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(actor_losses_list, label='Actor Loss', color='orange')\n",
        "    plt.xlabel('Training Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(critic_losses_list, label='Critic Loss', color='red')\n",
        "    plt.xlabel('Training Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Simple DDPG Training Completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5072e8ee",
      "metadata": {
        "id": "5072e8ee"
      },
      "outputs": [],
      "source": [
        "# Save Path\n",
        "save_path = \"/content/drive/MyDrive/actor_critic/\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save models\n",
        "th.save(actor.state_dict(), os.path.join(save_path, \"actor_new.pth\"))\n",
        "th.save(critic1.state_dict(), os.path.join(save_path, \"critic1_new.pth\"))\n",
        "th.save(critic2.state_dict(), os.path.join(save_path, \"critic2_new.pth\"))\n",
        "\n",
        "print(\"Models saved to Google Drive:\", save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Code"
      ],
      "metadata": {
        "id": "68CEwowwE6vK"
      },
      "id": "68CEwowwE6vK"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "28e39db7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28e39db7",
        "outputId": "01047ee2-d6db-43df-c900-98b188ea9825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Actor(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=3, bias=True)\n",
              "  )\n",
              "  (tanh): Tanh()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Create actor for eval\n",
        "actor = Actor(3, 3).to(device)\n",
        "\n",
        "# Load weights safely for CPU\n",
        "checkpoint = th.load(\"/content/drive/MyDrive/actor_critic/actor_new2.pth\", map_location=device)\n",
        "actor.load_state_dict(checkpoint)\n",
        "\n",
        "actor.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d4ba0f",
      "metadata": {
        "id": "02d4ba0f"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = th.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "test_dir = r\"/content/drive/MyDrive/Atri Dataset/Test\"\n",
        "\n",
        "# Lists for Validation Graphs\n",
        "all_conf_diffs = []\n",
        "iou_consistency = []\n",
        "entropy_orig_list, entropy_proc_list = [], []\n",
        "detections_diff = []\n",
        "\n",
        "for class_name in os.listdir(test_dir):\n",
        "    class_path = os.path.join(test_dir, class_name)\n",
        "\n",
        "    # Create a new environment for each class's images\n",
        "    env_eval = ImagePreprocessorEnv(class_path, model, steps=MAX_STEPS)\n",
        "\n",
        "    # For test image\n",
        "    for fname in os.listdir(class_path):\n",
        "\n",
        "        img_path = os.path.join(class_path, fname)\n",
        "        img = cv.imread(img_path)\n",
        "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "        # Prepare state\n",
        "        state = env_eval.reset()\n",
        "        state_tensor = th.FloatTensor(state).unsqueeze(0)\n",
        "\n",
        "        # Actor predicts action\n",
        "        with th.no_grad():\n",
        "            action = actor(state_tensor).cpu().numpy()[0]\n",
        "\n",
        "        # Apply transformation using env\n",
        "        img_proc = env_eval.transform(img_rgb, action)\n",
        "\n",
        "        results_orig = model(img_rgb)\n",
        "        results_proc = model(img_proc)\n",
        "\n",
        "        pred_orig = results_orig.pred[0].cpu().numpy()\n",
        "        pred_proc = results_proc.pred[0].cpu().numpy()\n",
        "\n",
        "        # Confidence diff\n",
        "        confs_orig = pred_orig[:, 4] if pred_orig.size > 0 else []\n",
        "        confs_proc = pred_proc[:, 4] if pred_proc.size > 0 else []\n",
        "        mean_orig = np.mean(confs_orig) if len(confs_orig) > 0 else 0\n",
        "        mean_proc = np.mean(confs_proc) if len(confs_proc) > 0 else 0\n",
        "        all_conf_diffs.append(mean_proc - mean_orig)\n",
        "\n",
        "        #  IoU consistency\n",
        "        if len(pred_orig) > 0 and len(pred_proc) > 0:\n",
        "\n",
        "            # Take top prediction\n",
        "            box_o = pred_orig[0][:4]\n",
        "            box_p = pred_proc[0][:4]\n",
        "\n",
        "            # IoU calculation\n",
        "            xA = max(box_o[0], box_p[0])\n",
        "            yA = max(box_o[1], box_p[1])\n",
        "            xB = min(box_o[2], box_p[2])\n",
        "            yB = min(box_o[3], box_p[3])\n",
        "            interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "            boxAArea = (box_o[2] - box_o[0]) * (box_o[3] - box_o[1])\n",
        "            boxBArea = (box_p[2] - box_p[0]) * (box_p[3] - box_p[1])\n",
        "            iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
        "            iou_consistency.append(iou)\n",
        "\n",
        "        #  Entropy of class probabilities\n",
        "        if len(pred_orig) > 0:\n",
        "            probs_o = pred_orig[:, 4] / np.sum(pred_orig[:, 4])  # normalize\n",
        "            entropy_orig_list.append(entropy(probs_o, base=2))\n",
        "        if len(pred_proc) > 0:\n",
        "            probs_p = pred_proc[:, 4] / np.sum(pred_proc[:, 4])\n",
        "            entropy_proc_list.append(entropy(probs_p, base=2))\n",
        "\n",
        "        # Detection count change\n",
        "        detections_diff.append(len(pred_proc) - len(pred_orig))\n",
        "\n",
        "# Confidence diff histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(all_conf_diffs, bins=20, color=\"skyblue\", edgecolor=\"black\", alpha=0.7)\n",
        "plt.axvline(0, color='red', linestyle='--', label=\"No Change\")\n",
        "plt.xlabel(\"Confidence Improvement (Processed - Original)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.title(\"Effect of RL Preprocessing on YOLOv5 Confidence\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# IoU consistency distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(iou_consistency, bins=20, color=\"orange\", edgecolor=\"black\", alpha=0.7)\n",
        "plt.xlabel(\"IoU between Original and Processed boxes\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.title(\"Prediction Consistency (IoU)\")\n",
        "plt.show()\n",
        "\n",
        "# Entropy before vs after\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(entropy_orig_list, label=\"Original Entropy\", alpha=0.7)\n",
        "plt.plot(entropy_proc_list, label=\"Processed Entropy\", alpha=0.7)\n",
        "plt.xlabel(\"Image Index\")\n",
        "plt.ylabel(\"Entropy (lower = more confident)\")\n",
        "plt.title(\"Prediction Confidence Sharpness\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Detection count difference\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(detections_diff, bins=20, color=\"green\", edgecolor=\"black\", alpha=0.7)\n",
        "plt.axvline(0, color='red', linestyle=\"--\", label=\"No Change\")\n",
        "plt.xlabel(\"Detections (Processed - Original)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.title(\"Change in Detection Count\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b7de178",
      "metadata": {
        "id": "7b7de178"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Collect all test images\n",
        "all_images = []\n",
        "for class_name in os.listdir(test_dir):\n",
        "    class_path = os.path.join(test_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for fname in os.listdir(class_path):\n",
        "            if fname.lower().endswith(('.jpg')):\n",
        "                all_images.append(os.path.join(class_path, fname))\n",
        "\n",
        "# Pick 5 random images\n",
        "sample_paths = random.sample(all_images, 5)\n",
        "\n",
        "plt.figure(figsize=(40, 30))\n",
        "\n",
        "for i, img_path in enumerate(sample_paths):\n",
        "    class_path = os.path.dirname(img_path)\n",
        "    env_eval = ImagePreprocessorEnv(class_path, model, steps=MAX_STEPS)\n",
        "\n",
        "    # Load image\n",
        "    img = cv.imread(img_path)\n",
        "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    # RL Agent processing\n",
        "    state = env_eval.reset()\n",
        "    state_tensor = th.FloatTensor(state).unsqueeze(0)\n",
        "    with th.no_grad():\n",
        "        action = actor(state_tensor).cpu().numpy()[0]\n",
        "    img_proc = env_eval.transform(img_rgb, action)\n",
        "\n",
        "    # Run YOLO\n",
        "    results_orig = model(img_rgb)\n",
        "    results_proc = model(img_proc)\n",
        "\n",
        "    # Annotated images\n",
        "    orig_annot = np.squeeze(results_orig.render())\n",
        "    proc_annot = np.squeeze(results_proc.render())\n",
        "\n",
        "    # Grid plotting\n",
        "    plt.subplot(5, 2, 2 * i + 1)\n",
        "    plt.imshow(orig_annot)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Original ({Path(img_path).stem})\")\n",
        "\n",
        "    plt.subplot(5, 2, 2 * i + 2)\n",
        "    plt.imshow(proc_annot)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Processed\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eILZqLCOxDNe"
      },
      "id": "eILZqLCOxDNe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}